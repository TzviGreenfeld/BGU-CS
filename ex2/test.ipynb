{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cvxopt import solvers, matrix, spmatrix, spdiag, sparse\n",
    "import matplotlib.pyplot as plt\n",
    "from softsvm import softsvm, fix_small_eigvals, error, get_random_sample\n",
    "import softsvm\n",
    "# unlimited np output\n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "data = np.load(r'G:\\My Drive\\uni\\Machine Learning intro\\Introduction-To-Machine-Learning\\ex2\\ex2q4_data.npz')\n",
    "trainX, testX = data['Xtrain'], data['Xtest']\n",
    "trainY, testY = data['Ytrain'], data['Ytest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K(dot_res, k):\n",
    "    \"\"\"\n",
    "    :param dot_res: dot product of two np.arrays\n",
    "    :param k: the degree of the poly kernel\n",
    "    :return: (1 + dot_res)^k\n",
    "    \"\"\"\n",
    "    return np.power(float(1) + dot_res, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gram_matrix(X, k):\n",
    "    G = np.dot(X, X.T)\n",
    "    # apply k to every item in G\n",
    "    G = np.vectorize(lambda sample: K(sample, k))(G)\n",
    "    return G\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softsvmpoly(l: float, k: int, trainX: np.array, trainy: np.array):\n",
    "    \"\"\"\n",
    "    :param l: the parameter lambda of the soft SVM algorithm\n",
    "    :param sigma: the bandwidth parameter sigma of the RBF kernel.\n",
    "    :param trainX: numpy array of size (m, d) containing the training sample\n",
    "    :param trainy: numpy array of size (m, 1) containing the labels of the training sample\n",
    "    :return: numpy array of size (m, 1) which describes the coefficients found by the algorithm\n",
    "    \"\"\"\n",
    "    m, d = trainX.shape\n",
    "    \n",
    "    G = get_gram_matrix(trainX, k)\n",
    "    G = fix_small_eigvals(G)\n",
    "\n",
    "    H = np.pad(float(2 * l) * G, [(0, m), (0, m)])\n",
    "    H = fix_small_eigvals(H)\n",
    "\n",
    "    A = np.block([[np.zeros((m, m)), np.identity(m)],\n",
    "                  [G * trainy.reshape(-1, 1), np.identity(m)]])\n",
    "    A = fix_small_eigvals(A)\n",
    "\n",
    "    _G = min(np.linalg.eigvals(G))\n",
    "    _H = min(np.linalg.eigvals(H))\n",
    "    _A = min(np.linalg.eigvals(A))\n",
    "    print(\"_G, _H, _A\")\n",
    "    print(_G, _H, _A)\n",
    "    # A has negative eigenvalues!\n",
    "\n",
    "    u = np.hstack((np.full(m, float(0)), np.full(m, 1/m)))\n",
    "\n",
    "    v = np.hstack((np.zeros(m), np.ones(m)))\n",
    "  \n",
    "    z = solvers.qp(matrix(H), matrix(u), -matrix(A), -matrix(v))\n",
    "    alphas = np.array(z[\"x\"])[:m]\n",
    "    return alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_G, _H, _A\n",
      "5.89698983965154e+31 2.220446049250313e-16 (-4.51955588371513e+17+0j)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0000e-02  1.0000e+00  2e+02  1e+00  7e+35\n",
      " 1:  9.7039e-01 -1.9703e+00  3e+00  1e-02  7e+33\n",
      " 2:  2.5568e-01 -1.2722e-02  3e-01  1e-04  7e+31\n",
      " 3:  2.5817e-03 -1.0192e-04  3e-03  1e-06  7e+29\n",
      " 4:  2.5817e-05 -1.0166e-06  3e-05  1e-08  7e+27\n",
      " 5:  2.5817e-07 -1.0166e-08  3e-07  1e-10  7e+25\n",
      " 6:  2.5817e-09 -1.0166e-10  3e-09  1e-12  7e+23\n",
      " 7:  2.5817e-11 -1.0166e-12  3e-11  1e-14  7e+21\n",
      " 8:  2.5817e-13 -1.0166e-14  3e-13  2e-15  7e+19\n",
      " 9:  2.5817e-15 -1.0166e-16  3e-15  2e-15  7e+17\n",
      "10:  2.5817e-17 -1.0166e-18  3e-17  2e-15  7e+15\n",
      "11:  2.5817e-19 -1.0166e-20  3e-19  2e-15  7e+13\n",
      "12:  2.5817e-21 -1.0166e-22  3e-21  2e-15  7e+11\n",
      "13:  2.5817e-23 -1.0166e-24  3e-23  2e-15  7e+09\n",
      "14:  2.5820e-25 -1.0167e-26  3e-25  1e-15  7e+07\n",
      "15:  2.6056e-27 -1.0241e-28  3e-27  2e-15  7e+05\n",
      "16:  4.6420e-29 -1.2808e-30  5e-29  1e-15  1e+04\n",
      "17:  7.9877e-30  5.9062e-31  7e-30  1e-15  2e+03\n",
      "18:  4.3657e-30  5.9580e-31  4e-30  1e-15  7e+02\n",
      "19:  1.1409e-30  7.9331e-31  3e-31  2e-15  1e-12\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "def simple_test():\n",
    "    # load question 2 data\n",
    "    data = np.load('EX2q2_mnist.npz')\n",
    "    trainX = data['Xtrain']\n",
    "    testX = data['Xtest']\n",
    "    trainy = data['Ytrain']\n",
    "    testy = data['Ytest']\n",
    "\n",
    "    m = 100\n",
    "\n",
    "    # Get a random m training examples from the training set\n",
    "    indices = np.random.permutation(trainX.shape[0])\n",
    "    _trainX = trainX[indices[:m]]\n",
    "    _trainy = trainy[indices[:m]]\n",
    "\n",
    "    # run the softsvmpoly algorithm\n",
    "    w = softsvmpoly(10, 5, _trainX, _trainy)\n",
    "\n",
    "    # tests to make sure the output is of the intended class and shape\n",
    "    assert isinstance(\n",
    "        w, np.ndarray), \"The output of the function softsvmbf should be a numpy array\"\n",
    "    assert w.shape[0] == m and w.shape[\n",
    "        1] == 1, f\"The shape of the output should be ({m}, 1)\"\n",
    "simple_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian_product(set_a: np.array, set_b: np.array):\n",
    "    return [(ai, bi) for ai in set_a for bi in set_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(alphas: np.array, k: int, testX: np.array):\n",
    "    \"\"\"\n",
    "    :param alphas: numpy array of size (m, 1) containing the coefficients of the soft SVM algorithm\n",
    "    :param testX: numpy array of size (m, d) containing the test sample\n",
    "    :param k: int, the degree of the poly kernel\n",
    "    :return: numpy array of size (m, 1) containing the predicted labels of the test sample\n",
    "    \"\"\"\n",
    "    G = get_gram_matrix(testX, k)\n",
    "    return np.sign(np.dot(G, alphas)) #TODO: shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(folds: int):\n",
    "    X_chunks = np.array(np.split(trainX, folds))\n",
    "    Y_chunks = np.array(np.split(trainY, folds))\n",
    "    splitted = []\n",
    "    shp = X_chunks.shape\n",
    "    for i in range(folds):\n",
    "        train, train_labales = X_chunks[i], Y_chunks[i]\n",
    "        # current test set is the the entire train besides the current chunk used for training\n",
    "        test = np.concatenate(np.delete(X_chunks, i, axis=0))\n",
    "        test_labales = np.concatenate(np.delete(Y_chunks, i, axis=0))\n",
    "        splitted.append({\"train\": train,\n",
    "                        \"train_labales\": train_labales,\n",
    "                        \"test\": test,\n",
    "                        \"test_labales\": test_labales})\n",
    "    return splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_cross_validation(lambdas: np.array, ks, folds: int):\n",
    "    \"\"\"\n",
    "    find pair (lambda, k) with the lowest validation error, and get classifier based on that pair\n",
    "    :param lambdas: the lambda parameters to use\n",
    "    :param ks: the k parameters to use in the kernel function\n",
    "    :param folds: number of chunks we split the data to\n",
    "    :return: prediction of test set of classifier trained on the entire train set using best lambda and k found\n",
    "    \"\"\"\n",
    "    # poly softSVM\n",
    "    errors = {(l, k): 0 for l, k in cartesian_product(lambdas, ks)}\n",
    "    for fold in split_data(folds):\n",
    "        for l, k in cartesian_product(lambdas, ks):\n",
    "            alphas = softsvmpoly(l, k, fold[\"train\"], fold[\"train_labales\"])\n",
    "            predicted = predict(alphas, k, fold[\"test\"])\n",
    "            # continuesly calculate the avg error\n",
    "            errors[(l, k)] += error(fold[\"test_labales\"], predicted) / folds\n",
    "    \n",
    "    # get the pair with lowest avg error\n",
    "    best_lambda, best_k = min(error.items(), key=lambda x: x[1])[0]\n",
    "    print(f\"best_lambda={best_lambda}, best_k={best_k}\")\n",
    "    alphas = softsvmpoly(best_lambda, best_k, trainX, trainY)\n",
    "    predict(alphas, best_k, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softsvm_cross_validation(lambdas, folds):\n",
    "    errors = {l: 0 for l in lambdas}\n",
    "    for fold in split_data(folds):\n",
    "        for l in lambdas:\n",
    "            w = softsvm(l, fold[\"train\"], fold[\"train_labales\"])\n",
    "            errors[l] += error(fold[\"test_labales\"], softsvm.predict(w, fold[\"test\"])) / folds\n",
    "    \n",
    "    # get the l with lowest avg error\n",
    "    best_lambda = min(error.items(), key=lambda x: x[1])[0]\n",
    "    print(f\"best_lambda={best_lambda}\")\n",
    "    w = softsvm(best_lambda, trainX, trainY)\n",
    "    softsvm.predict(w, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_error():\n",
    "    \"\"\"\n",
    "    returns the error on test sample of\n",
    "    clasiisfier from poly_cross_validation with 5 folds\n",
    "    \"\"\"\n",
    "    lambdas = np.array([1, 10, 100])\n",
    "    ks = np.array([2, 5, 8])\n",
    "\n",
    "    # polynomial kernel\n",
    "    poly_predicions = poly_cross_validation(lambdas, ks, 5)\n",
    "    poly_error =  error(testY, poly_predicions)\n",
    "\n",
    "    # linear softsvm\n",
    "    soft_svm_predictions = poly_cross_validation(lambdas, ks, 5)\n",
    "    soft_svm_error =  error(testY, soft_svm_predictions)\n",
    "    print(f\"soft_svm_error={soft_svm_error}\")\n",
    "    print(f\"poly_error={poly_error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Rank(A) < p or Rank([P; A; G]) < n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArithmeticError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tzvig\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\cvxopt\\misc.py\u001b[0m in \u001b[0;36mfactor\u001b[1;34m(W, H, Df)\u001b[0m\n\u001b[0;32m   1428\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'S'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m                     \u001b[0mlapack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpotrf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'S'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1430\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mArithmeticError\u001b[0m: 7",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mArithmeticError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tzvig\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\cvxopt\\coneprog.py\u001b[0m in \u001b[0;36mconeqp\u001b[1;34m(P, q, G, h, dims, A, b, initvals, kktsolver, xnewcopy, xdot, xaxpy, xscal, ynewcopy, ydot, yaxpy, yscal, **kwargs)\u001b[0m\n\u001b[0;32m   2064\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mrti\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rti'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrti\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mrti\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2065\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2066\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mArithmeticError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tzvig\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\cvxopt\\coneprog.py\u001b[0m in \u001b[0;36mkktsolver\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m   1980\u001b[0m          \u001b[1;32mdef\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1981\u001b[1;33m              \u001b[1;32mreturn\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tzvig\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\cvxopt\\misc.py\u001b[0m in \u001b[0;36mfactor\u001b[1;34m(W, H, Df)\u001b[0m\n\u001b[0;32m   1443\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'S'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1444\u001b[1;33m                     \u001b[0mlapack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpotrf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'S'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1445\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mArithmeticError\u001b[0m: 7",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3612\\2791984410.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# def Q4_b():\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#     cross_validation_error()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcross_validation_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3612\\1375405541.py\u001b[0m in \u001b[0;36mcross_validation_error\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# polynomial kernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mpoly_predicions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoly_cross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mpoly_error\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoly_predicions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3612\\3067377427.py\u001b[0m in \u001b[0;36mpoly_cross_validation\u001b[1;34m(lambdas, ks, folds)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcartesian_product\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0malphas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftsvmpoly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"train_labales\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"test\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;31m# continuesly calculate the avg error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3612\\1826111206.py\u001b[0m in \u001b[0;36msoftsvmpoly\u001b[1;34m(l, k, trainX, trainy)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolvers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0malphas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0malphas\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tzvig\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\cvxopt\\coneprog.py\u001b[0m in \u001b[0;36mqp\u001b[1;34m(P, q, G, h, A, b, solver, kktsolver, initvals, **kwargs)\u001b[0m\n\u001b[0;32m   4483\u001b[0m             'residual as dual infeasibility certificate': dinfres}\n\u001b[0;32m   4484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4485\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconeqp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkktsolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\tzvig\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\cvxopt\\coneprog.py\u001b[0m in \u001b[0;36mconeqp\u001b[1;34m(P, q, G, h, dims, A, b, initvals, kktsolver, xnewcopy, xdot, xaxpy, xscal, ynewcopy, ydot, yaxpy, yscal, **kwargs)\u001b[0m\n\u001b[0;32m   2065\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2066\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mArithmeticError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2067\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Rank(A) < p or Rank([P; A; G]) < n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Rank(A) < p or Rank([P; A; G]) < n"
     ]
    }
   ],
   "source": [
    "# def Q4_b():\n",
    "#     cross_validation_error()\n",
    "cross_validation_error()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84a7aaf0e4ebd1344d203018763ba60d6cff13f7f17c982bfbf7f577312bada9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
